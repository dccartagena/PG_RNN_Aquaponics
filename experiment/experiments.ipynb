{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate time-series forecasting for Aquaponics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "Implementation of physics-guided recurrent neural networks (PG-RNN) as architecture to forecast relevant variables in Aquaponics. The main advantage of this architecture is the inclusion of theory-based knowledge into deep learning models as a constraint optimization formulation. The resulting PGNN model will be used in a model-based reinforcement learning framework.\n",
    "\n",
    "Target variables to forecast:\n",
    "* pH\n",
    "* Dissolved oxygen\n",
    "* Vegetable weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries: \n",
    "* PyTorch for deep learning model design\n",
    "* TensorBoard for model training visualization\n",
    "* Pandas, Numpy, MatplotLib for scientific computing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "# Torch utilities\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Distributed computing\n",
    "# import horovod.torch as hvd\n",
    "import torch.utils.data.distributed\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "# Scientific computing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expose GPUs\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" \n",
    "\n",
    "# Setup plotting parameters\n",
    "mpl.rcParams['figure.figsize'] = (14, 8)\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "font = {'size'   : 18}\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "# Random seed\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code checklist\n",
    "* Data\n",
    "    * Data asquisition\n",
    "    * Data pre-processing\n",
    "        * Outliers removal\n",
    "        * Noise filtering\n",
    "        * Missing data filling\n",
    "    * Data architecture - Time-series\n",
    "* Model\n",
    "    * Model design:\n",
    "        * Baseline model: \n",
    "            * Recurrent Neural Network\n",
    "            * Feed-fordward Neural Network\n",
    "        * Physics-guided Neural Network\n",
    "            * How to include constraints in the model? \n",
    "    * Experiment design:\n",
    "        * Training/evaluation routine\n",
    "        * Multi-GPU training\n",
    "* Experiments\n",
    "    * Training\n",
    "    * Validation\n",
    "    * Results visualization - TensorBoard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing\n",
    "* Pre-processing routine to remove outliers, fill missing data and denoise signals from aquaponics.\n",
    "* The data comes from an aquaponics between October 15th to December 4th (Fall/Winter)\n",
    "* The variables to analyze are:\n",
    "    * Water flow between tanks\n",
    "    * Dissolved oxygen\n",
    "    * pH in sump tank\n",
    "    * Water supplied\n",
    "    * Water temperature\n",
    "    * Water level\n",
    "    * Motor pump output\n",
    "    * Fish food\n",
    "    * CO2\n",
    "    * Light\n",
    "    * Vegetables weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_aquaponics_04_10_2021_15_12_2021.cvs.gz\n"
     ]
    }
   ],
   "source": [
    "def read_file(textfile):\n",
    "    df = pd.read_csv(textfile, compression='zip', sep=\"\\t\")\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    print('Dataset ready')\n",
    "    return df\n",
    "\n",
    "# Format dd_mm_yyyy\n",
    "# date_start  = '04_10_2021'\n",
    "# date_end    = '15_12_2021'\n",
    "\n",
    "# Format ddmmyyyy\n",
    "date_start = '04012021' \n",
    "date_end = '04302021'   \n",
    "\n",
    "file_name = 'dataset_aquaponics_{}_{}.txt.zip'.format(date_start, date_end)\n",
    "df = read_file(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop corrupted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_signal = [3, 12, 13, 14, 15, 22, 23, 24, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 56, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 93, 94, 95, 97, 98, 99, 100, 101, 104, 105, 106, 111, 112, 113, 114]\n",
    "df.drop(columns = drop_signal, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Denoise signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed-fordward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PG-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PG-GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-GPU processing\n",
    "\n",
    "def multi_gpu_training(train_dataset, model, batch_size):\n",
    "    # Initialize Horovod\n",
    "    hvd.init()\n",
    "\n",
    "    # Pin GPU to be used to process local rank (one GPU per process)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.set_device(hvd.local_rank())\n",
    "\n",
    "    # Partition dataset among workers using DistributedSampler\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        train_dataset, \n",
    "        num_replicas = hvd.size(), \n",
    "        rank = hvd.rank())\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size= batch_size, \n",
    "        sampler = train_sampler)\n",
    "\n",
    "    # Build model...\n",
    "    model.cuda()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters())\n",
    "\n",
    "    # Add Horovod Distributed Optimizer\n",
    "    optimizer = hvd.DistributedOptimizer(\n",
    "        optimizer, \n",
    "        named_parameters = model.named_parameters())\n",
    "\n",
    "    # Broadcast parameters from rank 0 to all other processes.\n",
    "    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{}]\\tLoss: {}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_sampler), loss.item()))\n",
    "    \n",
    "    return "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d61e67d4406f83661a218a7594034be74564666d0640d3900a3e99845865d0f0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
